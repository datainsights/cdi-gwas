{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "240a8280",
   "metadata": {},
   "source": [
    "# (PART) DATA EXPLORATION {-}\n",
    "# How do you create a GWAS project directory ready for analysis?\n",
    "\n",
    "## Explanation  \n",
    "Before working with data, it's important to set up a clean and organized project directory. A consistent folder structure helps you manage scripts, datasets, and outputs across both Python and R — making your work easier to follow and share.\n",
    "\n",
    "In this guide, we’ll create a root directory called `gwas-data-science` with four folders:\n",
    "\n",
    "- `data/` – for datasets  \n",
    "- `scripts/` – for code files  \n",
    "- `images/` – for plots and charts  \n",
    "- `library/` – for reusable functions  \n",
    "\n",
    "---\n",
    "\n",
    "**Example Folder Structure:**\n",
    "\n",
    "```plaintext\n",
    "gwas-data-science/\n",
    "├── data/\n",
    "├── scripts/\n",
    "├── images/\n",
    "└── library/\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Bash (Terminal)\n",
    "\n",
    "You can create the entire structure using this single command:\n",
    "\n",
    "```bash\n",
    "mkdir -p gwas-data-science/{data,scripts,images,library}\n",
    "cd gwas-data-science\n",
    "```\n",
    "\n",
    "## Python Code\n",
    "\n",
    "You can also create the same folder structure in Python:\n",
    "\n",
    "\n",
    "```python\n",
    "import os\n",
    "\n",
    "folders = [\"data\", \"scripts\", \"images\", \"library\"]\n",
    "root = \"gwas-data-science\"\n",
    "\n",
    "os.makedirs(root, exist_ok=True)\n",
    "for folder in folders:\n",
    "    os.makedirs(os.path.join(root, folder), exist_ok=True)\n",
    "\n",
    "print(f\"Created '{root}' project folder with subdirectories.\")\n",
    "```\n",
    "\n",
    "## R Code\n",
    "\n",
    "Here’s how to do it in R:\n",
    "\n",
    "```R\n",
    "folders <- c(\"data\", \"scripts\", \"images\", \"library\")\n",
    "root <- \"gwas-data-science\"\n",
    "\n",
    "if (!dir.exists(root)) dir.create(root)\n",
    "for (folder in folders) {\n",
    "  dir.create(file.path(root, folder), showWarnings = FALSE)\n",
    "}\n",
    "\n",
    "cat(\"Created\", root, \"project folder with subdirectories.\\n\")\n",
    "```\n",
    "\n",
    "> ✅ A clean project directory helps you stay organized, reuse code, and avoid errors — it’s the first step toward reproducible, professional data science.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd61ec53",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "\n",
    "```{r}\n",
    "library(tidyverse)\n",
    "library(rrBLUP)\n",
    "library(BGLR)\n",
    "library(DT)\n",
    "library(SNPRelate)\n",
    "library(qqman)\n",
    "library(poolr)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314120d9",
   "metadata": {},
   "source": [
    "# How do you prepare a public GWAS dataset for R-based analysis?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "To support reproducible and cross-platform workflows, it's helpful to separate raw data preparation from your analysis code. In this example, we use a Bash script to download and organize a publicly available rice diversity panel dataset from [Zhao et al., 2011](http://ricediversity.org/data/sets/44kgwas/).\n",
    "\n",
    "The script performs the following steps:\n",
    "\n",
    "- 📥 Downloads PLINK-formatted genotype files (`.ped`, `.map`, `.fam`)  \n",
    "- 📦 Unzips and flattens the directory structure for easy access  \n",
    "- 🏷️ Renames the phenotype file for clarity (`sativa413_phenotypes.txt`)  \n",
    "- 📁 Moves all outputs into a consistent `data/` directory with a `sativa413_` prefix\n",
    "\n",
    "This setup creates a clean and well-organized foundation for downstream R-based GWAS analysis.\n",
    "\n",
    "## Bash Script\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "\n",
    "# 🚀 Prepare rice GWAS genotype and phenotype data (PLINK format)\n",
    "\n",
    "# --- Paths and filenames ---\n",
    "ZIP_URL=\"http://ricediversity.org/data/sets/44kgwas/RiceDiversity.44K.MSU6.Genotypes_PLINK.zip\"\n",
    "ZIP_FILE=\"data/rice_gwas_genotypes.zip\"\n",
    "EXTRACT_DIR=\"data/RiceDiversity_44K_Genotypes_PLINK\"\n",
    "PHENO_URL=\"http://www.ricediversity.org/data/sets/44kgwas/RiceDiversity_44K_Phenotypes_34traits_PLINK.txt\"\n",
    "PHENO_OUT=\"data/sativa413_phenotypes.txt\"\n",
    "\n",
    "# --- Step 1: Ensure data folder exists ---\n",
    "mkdir -p data\n",
    "\n",
    "# --- Step 2: Download genotype zip file (if not already present) ---\n",
    "if [ ! -f \"$ZIP_FILE\" ]; then\n",
    "  echo \"⬇️ Downloading genotype data...\"\n",
    "  wget --no-check-certificate -O \"$ZIP_FILE\" \"$ZIP_URL\"\n",
    "else\n",
    "  echo \"✅ Genotype zip already exists: $ZIP_FILE\"\n",
    "fi\n",
    "\n",
    "# --- Step 3: Unzip genotype data ---\n",
    "echo \"📂 Extracting genotype files...\"\n",
    "unzip -o \"$ZIP_FILE\" -d data/\n",
    "\n",
    "# --- Step 4: Move files up and clean nested folder ---\n",
    "if [ -d \"$EXTRACT_DIR\" ]; then\n",
    "  mv \"$EXTRACT_DIR\"/* data/\n",
    "  rm -rf \"$EXTRACT_DIR\"\n",
    "fi\n",
    "rm -rf data/__MACOSX\n",
    "rm -f \"$ZIP_FILE\"\n",
    "\n",
    "# --- Step 5: Download phenotype file and rename ---\n",
    "echo \"⬇️ Downloading phenotype file...\"\n",
    "wget --no-check-certificate -P data/ \"$PHENO_URL\"\n",
    "mv data/RiceDiversity_44K_Phenotypes_34traits_PLINK.txt \"$PHENO_OUT\"\n",
    "\n",
    "echo \"✅ GWAS data successfully prepared in the data/ folder.\"\n",
    "```\n",
    "\n",
    "The Bash script is saved as:  \n",
    "\n",
    "```bash\n",
    "script/gwas_data.sh\n",
    "```\n",
    "\n",
    "To run it:\n",
    "\n",
    "```bash\n",
    "bash script/gwas_data.sh\n",
    "```\n",
    "\n",
    "## File Structure\n",
    "After execution, the `data/` folder contains:\n",
    "\n",
    "```\n",
    "project/\n",
    "├── script/\n",
    "│   └── gwas_data.sh\n",
    "└── data/\n",
    "    ├── sativa413.map\n",
    "    ├── sativa413.ped\n",
    "    ├── sativa413.fam\n",
    "    └── sativa413_phenotypes.txt\n",
    "```\n",
    "\n",
    "> ✅ **Takeaway:** Using a Bash script to automate dataset download and organization keeps your R analysis environment clean, standardized, and fully reproducible. All required files are now available in the `data/` folder under the `sativa413_` prefix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceda5f9",
   "metadata": {},
   "source": [
    "# How do you efficiently load and store GWAS data files in R?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "GWAS datasets can be large, especially the genotype file in `.ped` format, which stores two columns per SNP. Repeatedly reading this file is time-consuming, so it’s best to:\n",
    "\n",
    "- Load it once using `readr::read_table()` for speed and consistency.\n",
    "- Save the loaded object as a compressed `.rds` file for fast future access.\n",
    "- Load supporting metadata files (`.map`, `.fam`) and phenotype data using consistent column names.\n",
    "\n",
    "All files are stored in the `data/` directory and prefixed with `sativa413_`.\n",
    "\n",
    "## R Code\n",
    "\n",
    "```{r}\n",
    "library(tidyverse)\n",
    "\n",
    "# Step 1: Load genotype data using readr\n",
    "ped_data <- read_table(\"data/sativas413.ped\", col_names = FALSE, show_col_types = FALSE)\n",
    "\n",
    "# Step 2: Save as compressed RDS file\n",
    "write_rds(ped_data, file = \"data/sativas413.rds\")\n",
    "\n",
    "# Step 3: Load metadata files\n",
    "map_data <- read_table(\"data/sativas413.map\", \n",
    "                       col_names = c(\"chr\", \"snp_id\", \"gen_dist\", \"bp_pos\"), \n",
    "                       show_col_types = FALSE)\n",
    "\n",
    "fam_data <- read_table(\"data/sativas413.fam\", \n",
    "                       col_names = c(\"FID\", \"IID\", \"PID\", \"MID\", \"sex\", \"phenotype\"), \n",
    "                       show_col_types = FALSE)\n",
    "\n",
    "phenotype_data <- read_tsv(\"data/sativa413_phenotypes.txt\", show_col_types = FALSE)\n",
    "```\n",
    "\n",
    "> ✅ **Takeaway:** For large genotype files, load once using `readr`, save as `.rds`, and always use clear column names when importing metadata and phenotype files to streamline analysis and ensure reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f9f8a8",
   "metadata": {},
   "source": [
    "# How do you inspect the structure and contents of GWAS input files in R?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "Before analysis, it’s essential to preview each file to check:\n",
    "\n",
    "- Row and column dimensions\n",
    "- Sample ID consistency\n",
    "- General format of genotype and phenotype data\n",
    "\n",
    "This ensures everything is aligned before tidying or merging.\n",
    "\n",
    "## R Code\n",
    "\n",
    "```{r}\n",
    "# Load genotype file (if needed)\n",
    "ped_data <- read_rds(\"data/sativas413.rds\")\n",
    "\n",
    "# Check size of each file\n",
    "dim(ped_data)         # Genotype matrix\n",
    "dim(map_data)         # SNP metadata\n",
    "dim(fam_data)         # Sample info\n",
    "dim(phenotype_data)   # Trait info\n",
    "\n",
    "# Preview first few rows and columns\n",
    "head(ped_data[, 1:5])        # First 5 genotype columns (show alleles)\n",
    "head(map_data)\n",
    "head(fam_data[, 1:5])\n",
    "head(phenotype_data[, 1:5])\n",
    "```\n",
    "\n",
    "> ✅ **Takeaway:** Use `dim()` and `head()` to quickly check file structure and confirm that samples and traits align before transforming or analyzing GWAS data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9823c0",
   "metadata": {},
   "source": [
    "# How do you tidy the genotype matrix from a `.ped` file in R?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "PLINK `.ped` files store genotype data in a wide format, where each SNP is represented by **two columns per individual** (one for each allele). This structure is inefficient for downstream analysis, so we convert it to a **tidy format** where:\n",
    "\n",
    "- Each row represents one sample\n",
    "- Each column represents one SNP\n",
    "- Alleles are combined (e.g., `\"A A\"`, `\"A G\"`, `\"G G\"`)\n",
    "\n",
    "We also use SNP metadata from the `.map` file — now consistently referred to as `snp_info` — to label the columns.\n",
    "\n",
    "## R Code\n",
    "\n",
    "```{r}\n",
    "# Load necessary library\n",
    "library(tidyverse)\n",
    "\n",
    "# Step 1: Load genotype and SNP info (if not already in memory)\n",
    "ped_data <- read_rds(\"data/sativas413.rds\")\n",
    "snp_info <- read_table(\"data/sativas413.map\", \n",
    "                       col_names = c(\"chr\", \"snp_id\", \"gen_dist\", \"bp_pos\"), \n",
    "                       show_col_types = FALSE)\n",
    "\n",
    "# Step 2: Separate sample IDs and genotype calls\n",
    "sample_ids <- ped_data[, 1:2]              # FID and IID\n",
    "genotype_matrix <- ped_data[, -(1:6)]      # Alleles only\n",
    "\n",
    "# Step 3: Verify expected SNP count\n",
    "n_snps <- ncol(genotype_matrix) / 2\n",
    "stopifnot(n_snps == nrow(snp_info))\n",
    "\n",
    "# Step 4: Combine each pair of allele columns into genotype strings\n",
    "genotype_calls <- map_dfc(seq(1, ncol(genotype_matrix), by = 2), function(i) {\n",
    "  paste(genotype_matrix[[i]], genotype_matrix[[i + 1]])\n",
    "})\n",
    "names(genotype_calls) <- snp_info$snp_id  # Use SNP IDs as column names\n",
    "\n",
    "# Step 5: Combine with sample IDs\n",
    "genotype_tidy <- bind_cols(sample_ids, genotype_calls)\n",
    "\n",
    "# Step 6: Preview output\n",
    "head(genotype_tidy[1:10, 1:5])  # Show FID, IID, and first 8 SNPs\n",
    "glimpse(genotype_tidy[1:5, 1:10])  # Show FID, IID, and first 8 SNPs\n",
    "```\n",
    "\n",
    "> ✅ **Takeaway:** Tidying `.ped` genotype data into a clean sample-by-SNP format makes it much easier to analyze, visualize, or convert to numeric dosages. Use `snp_info` consistently as the SNP metadata reference to avoid conflicts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36603b97",
   "metadata": {},
   "source": [
    "# How do you recode allele strings into numeric count format for GWAS?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "After tidying the `.ped` genotype matrix into a clean format where each SNP column contains values like `\"A A\"`, `\"A G\"`, or `\"G G\"`, most GWAS tools require those genotypes to be **numeric**:\n",
    "\n",
    "> **Genotype count format:**  \n",
    "> - `0` = Homozygous for major allele  \n",
    "> - `1` = Heterozygous  \n",
    "> - `2` = Homozygous for minor allele  \n",
    "> - `NA` = Missing or uncalled genotype\n",
    "\n",
    "To do this, we:\n",
    "\n",
    "1. Identify the two alleles observed at each SNP  \n",
    "2. Determine the **minor allele** (less frequent)  \n",
    "3. Count how many copies of the **minor allele** each individual has (`0`, `1`, or `2`)\n",
    "\n",
    "---\n",
    "\n",
    "✅ **Clarifying the structure of the genotype matrix:**\n",
    "\n",
    "Each pair of alleles (like `\"A G\"`, `\"G G\"`, `\"T C\"`) represents a **genotype** for a single SNP in a single individual.\n",
    "\n",
    "So when you load the `.ped` file and separate it into allele pairs:\n",
    "\n",
    "- **Each pair** = one **genotype**  \n",
    "- **Each column** = one **SNP**  \n",
    "- **Each row** = one **sample**\n",
    "\n",
    "> 🧠 This distinction is important when converting genotype strings to numeric formats for GWAS.\n",
    "\n",
    "## R Code\n",
    "\n",
    "```{r}\n",
    "# Load libraries\n",
    "library(tidyverse)\n",
    "\n",
    "# Step 1: Drop FID and IID from genotype_tidy to isolate genotype columns\n",
    "geno_alleles <- genotype_tidy[, -c(1, 2)]\n",
    "\n",
    "# Step 2: Convert allele strings to numeric minor allele counts\n",
    "geno_minor_allele_count <- map_dfc(geno_alleles, function(allele_vec) {\n",
    "  # Split all genotype strings (e.g., \"A G\") into individual alleles\n",
    "  alleles <- unlist(str_split(allele_vec, \" \"))\n",
    "  allele_counts <- table(alleles)\n",
    "\n",
    "  # Skip SNPs that are monomorphic or malformed\n",
    "  if (length(allele_counts) < 2) return(rep(NA, length(allele_vec)))\n",
    "\n",
    "  # Identify the minor allele (less frequent)\n",
    "  minor_allele <- names(sort(allele_counts))[1]\n",
    "\n",
    "  # Count how many copies of the minor allele are in each genotype\n",
    "  sapply(allele_vec, function(gt) {\n",
    "    if (gt %in% c(\"0 0\", \"0 1\", \"1 0\", \"1 1\", \"0\", \"1\")) return(NA)  # filter malformed\n",
    "    split_alleles <- unlist(str_split(gt, \" \"))\n",
    "    if (length(split_alleles) != 2) return(NA)\n",
    "    sum(split_alleles == minor_allele)\n",
    "  })\n",
    "})\n",
    "\n",
    "# Step 3: Add back sample identifiers\n",
    "genotype_count <- bind_cols(genotype_tidy[, 1:2], geno_minor_allele_count)\n",
    "\n",
    "# Step 4: Preview the cleaned matrix\n",
    "glimpse(genotype_count[, 1:5])\n",
    "```\n",
    "\n",
    "> ✅ **Takeaway:** Recoding genotype strings into numeric dosages (0, 1, 2) is essential for statistical GWAS models. It standardizes input and prepares your data for PCA, association testing, or genomic prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ce0bed",
   "metadata": {},
   "source": [
    "# How do you filter SNPs and samples based on missing data and minor allele frequency?\n",
    "<!-- # How do you filter genotype data for missingness and minor allele frequency? -->\n",
    "\n",
    "## Explanation\n",
    "\n",
    "Before running GWAS, it's important to apply basic quality control (QC) to the genotype matrix. This ensures that:\n",
    "\n",
    "- SNPs with too many missing genotypes are excluded  \n",
    "- SNPs with very low variability (low minor allele frequency) are removed  \n",
    "- Samples with excessive missing data (optional) are filtered out  \n",
    "\n",
    "These steps improve statistical power and reduce false associations.\n",
    "\n",
    "## R Code\n",
    "\n",
    "```{r}\n",
    "# Load required libraries\n",
    "library(tidyverse)\n",
    "\n",
    "# Step 1: Remove sample columns (FID, IID)\n",
    "count_only <- genotype_count[, -c(1, 2)]\n",
    "\n",
    "# Step 2: Filter SNPs by missingness (e.g., keep SNPs with <10% missing values)\n",
    "snp_missing <- colMeans(is.na(count_only))\n",
    "snp_keep <- names(snp_missing[snp_missing < 0.1])\n",
    "filtered_count <- count_only[, snp_keep]\n",
    "\n",
    "# Step 3: Filter SNPs by minor allele frequency (MAF >= 0.05)\n",
    "calc_maf <- function(x) {\n",
    "  p <- mean(x, na.rm = TRUE) / 2\n",
    "  min(p, 1 - p)\n",
    "}\n",
    "snp_maf <- map_dbl(filtered_count, calc_maf)\n",
    "maf_keep <- names(snp_maf[snp_maf >= 0.05])\n",
    "final_count <- filtered_count[, maf_keep]\n",
    "\n",
    "# Step 4: Reattach FID and IID\n",
    "filtered_geno <- bind_cols(genotype_count[, 1:2], final_count)\n",
    "\n",
    "# Step 5: Summary of filtering\n",
    "cat(\"Original SNPs:\", ncol(count_only), \"\\n\")\n",
    "cat(\"After missing filter:\", length(snp_keep), \"\\n\")\n",
    "cat(\"After MAF filter:\", length(maf_keep), \"\\n\")\n",
    "```\n",
    "\n",
    "> ✅ **Takeaway:** Apply SNP-level filters for missing data and low MAF to improve data quality. This ensures that only informative and reliable markers are used in your GWAS analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084097a4",
   "metadata": {},
   "source": [
    "# How do you impute missing genotype values before GWAS analysis?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "Many GWAS and population structure methods (like PCA or kinship matrix computation) require complete genotype matrices. If you have filtered for missingness but still have a few `NA` values, a simple approach is to impute missing genotypes using the **mean dosage** for each SNP.\n",
    "\n",
    "This is fast, reproducible, and good enough for visualization and many linear models.\n",
    "\n",
    "## R Code\n",
    "\n",
    "```{r}\n",
    "# Load library\n",
    "library(tidyverse)\n",
    "\n",
    "# Step 1: Extract dosage matrix (without FID/IID)\n",
    "dosage_matrix <- filtered_geno[, -c(1, 2)]\n",
    "\n",
    "# Step 2: Impute missing values using column means\n",
    "imputed_matrix <- dosage_matrix %>%\n",
    "  mutate(across(everything(), ~ ifelse(is.na(.), mean(., na.rm = TRUE), .)))\n",
    "\n",
    "# Step 3: Add back FID and IID\n",
    "geno_imputed <- bind_cols(filtered_geno[, 1:2], imputed_matrix)\n",
    "\n",
    "# Step 4: Preview\n",
    "head(geno_imputed[, 1:5])\n",
    "glimpse(geno_imputed[1:5, 1:10])\n",
    "```\n",
    "\n",
    "> ✅ **Takeaway:** Simple mean imputation fills missing genotype values efficiently. It’s suitable for PCA, kinship, and linear models when high accuracy isn't critical or when advanced imputation isn't available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1612f97d",
   "metadata": {},
   "source": [
    "# How do you perform PCA on genotype data to assess population structure?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "PCA (Principal Component Analysis) is a standard method to explore genetic diversity and detect hidden population structure in GWAS datasets. It helps:\n",
    "\n",
    "- Control for confounding due to stratification  \n",
    "- Visualize sample clusters or outliers  \n",
    "- Generate covariates (`PC1`, `PC2`, etc.) for use in association models\n",
    "\n",
    "We apply PCA on the **imputed genotype dosage matrix**, excluding identifier columns (`FID`, `IID`), and then combine the results with sample IDs.\n",
    "\n",
    "## R Code\n",
    "\n",
    "```{r}\n",
    "# Load libraries\n",
    "library(tidyverse)\n",
    "\n",
    "# Step 1: Extract genotype matrix (exclude FID and IID)\n",
    "geno_numeric <- geno_imputed[, -c(1, 2)]\n",
    "\n",
    "# Step 2: Perform PCA using prcomp\n",
    "pca_result <- prcomp(geno_numeric, center = TRUE, scale. = TRUE)\n",
    "\n",
    "# Step 3: Combine first 5 PCs with sample IDs\n",
    "pca_df <- geno_imputed[, 1:2] %>%  # FID and IID\n",
    "  bind_cols(as_tibble(pca_result$x[, 1:5]))  # PC1 to PC5\n",
    "\n",
    "# Step 4: Plot PC1 vs PC2\n",
    "ggplot(pca_df, aes(x = PC1, y = PC2)) +\n",
    "  geom_point(size = 2, alpha = 0.7) +\n",
    "  labs(title = \"PCA of Genotype Data\", x = \"PC1\", y = \"PC2\") +\n",
    "  theme_minimal()\n",
    "```\n",
    "\n",
    "> ✅ **Takeaway:** PCA helps uncover hidden structure in your GWAS population. Always reattach `FID` and `IID` to PCA scores so they can be merged with phenotype and genotype metadata for downstream modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d948bf41",
   "metadata": {},
   "source": [
    "# How do you include PCA covariates in a GWAS model?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "To reduce false positives caused by hidden genetic structure, it's standard in GWAS to include the top principal components (PCs) as covariates in the model. These PCs come from PCA applied to the genotype matrix and must be matched back to each sample using the same identifiers (`FID`, `IID`).\n",
    "\n",
    "This Q&A walks through the process of combining phenotype, PCA, and genotype data, then fitting a single SNP-trait association model.\n",
    "\n",
    "## R Code\n",
    "\n",
    "```{r}\n",
    "# Load libraries\n",
    "library(tidyverse)\n",
    "\n",
    "# Step 1: Load and align phenotype data with sample metadata (by FID)\n",
    "fam_data <- read_table(\"data/sativas413.fam\", \n",
    "                       col_names = c(\"FID\", \"IID\", \"PID\", \"MID\", \"sex\", \"phenotype\"), \n",
    "                       show_col_types = FALSE)\n",
    "\n",
    "phenotype_data <- read_tsv(\"data/sativa413_phenotypes.txt\", show_col_types = FALSE) %>%\n",
    "  rename(FID = 1)  # Sample IDs in phenotype file match fam_data$FID\n",
    "\n",
    "sample_metadata <- left_join(fam_data, phenotype_data, by = \"FID\")\n",
    "\n",
    "# Step 2: Rename PCA columns to include proper IDs\n",
    "pca_df <- pca_df %>%\n",
    "  rename(FID = 1, IID = 2)\n",
    "\n",
    "# Step 3: Merge PCA data into sample metadata\n",
    "sample_data <- left_join(sample_metadata, pca_df, by = c(\"FID\", \"IID\"))\n",
    "\n",
    "# Step 4: Standardize ID columns in genotype data\n",
    "geno_imputed <- geno_imputed %>%\n",
    "  rename(FID = 1, IID = 2)\n",
    "\n",
    "# Step 5: Merge genotype with metadata\n",
    "geno_data <- geno_imputed[, -1]  # Drop FID, keep IID and SNPs\n",
    "gwas_input <- left_join(sample_data, geno_data, by = \"IID\")\n",
    "\n",
    "# Step 6: Select trait and covariates\n",
    "trait <- \"Plant height\"  # Use the column name as a string\n",
    "covariates <- c(\"PC1\", \"PC2\", \"PC3\")\n",
    "\n",
    "# Save the merged GWAS input to an RDS file for future use\n",
    "saveRDS(gwas_input, file = \"data/gwas_input.rds\")\n",
    "\n",
    "# Step 7: Construct the model formula\n",
    "snp_name <- names(geno_data)[2]  # Replace with desired SNP\n",
    "formula_str <- paste0(\"`\", trait, \"` ~ \", snp_name, \" + \", paste(covariates, collapse = \" + \"))\n",
    "model <- lm(as.formula(formula_str), data = gwas_input)\n",
    "\n",
    "# Step 8: View model summary\n",
    "summary(model)\n",
    "```\n",
    "\n",
    "> ✅ **Takeaway:** Always ensure PCA scores include correctly labeled `FID` and `IID` so they can be merged with metadata and genotype matrices before fitting GWAS models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3d0aa2",
   "metadata": {},
   "source": [
    "# How do you interpret GWAS model results with PCA covariates?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "Once a GWAS model is fitted using a phenotype (e.g., *Plant height*), a SNP, and population structure covariates (e.g., PC1–PC3), we interpret the results using the model summary. The key values to look for are:\n",
    "\n",
    "- **Estimate**: The effect size of each variable  \n",
    "- **Pr(>|t|)**: The *p-value*, used to determine significance  \n",
    "- **R-squared**: The proportion of variation in the trait explained by the model  \n",
    "- **Residuals**: The spread of errors not explained by the model  \n",
    "\n",
    "This example tests the association between SNP `id1000007` and *Plant height*, adjusting for PC1 to PC3.\n",
    "\n",
    "## R Model Output Summary\n",
    "\n",
    "| Coefficient   | Estimate  | Std. Error | t value | Pr(>|t|)  | Significance |\n",
    "|:---------------|:-----------|:------------|:---------|:-----------|:--------------|\n",
    "| (Intercept)   | 115.83448 | 1.04707    | 110.63  | < 2e-16   | ***          |\n",
    "| id1000007     | 2.17767   | 1.54100    | 1.413   | 0.158     |              |\n",
    "| PC1           | 0.20502   | 0.02761    | 7.426   | 7.49e-13  | ***          |\n",
    "| PC2           | -0.19534  | 0.04436    | -4.404  | 1.39e-05  | ***          |\n",
    "| PC3           | -0.29738  | 0.07399    | -4.019  | 7.05e-05  | ***          |\n",
    "\n",
    "**Model Fit:**\n",
    "\n",
    "- Residual standard error: **18.63**\n",
    "- Degrees of freedom: **378**\n",
    "- R-squared: **0.2277**\n",
    "- Adjusted R-squared: **0.2195**\n",
    "- F-statistic: **27.86 on 4 and 378 DF**\n",
    "- Overall p-value: **< 2.2e-16**\n",
    "\n",
    "> ✅ **Takeaway:** This SNP is not significant (`p = 0.158`), but PCs show strong association with plant height. Controlling for population structure is essential to avoid false signals in GWAS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf81b28",
   "metadata": {},
   "source": [
    "# (PART) GWAS ANALYSIS & VIZ {-}\n",
    "\n",
    "# How do you perform a genome-wide SNP scan to generate GWAS results?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "Once you’ve merged your phenotype, PCA covariates, and genotype matrix into a single data frame (`gwas_input`), you can perform a **genome-wide association scan**.\n",
    "\n",
    "This involves fitting a linear model for each SNP, adjusting for population structure (e.g., PCs), and extracting the **effect size** and **p-value** for each SNP. These results are saved in a table for downstream visualization using Manhattan or QQ plots.\n",
    "\n",
    "Each model looks like:\n",
    "\n",
    "*Plant height ~ PC1 + PC2 + PC3 + SNP_i*\n",
    "\n",
    "We loop over all SNP columns in the dataset that match known prefixes (`id`, `ud`, `wd`, `dd`, `fd`) and collect the outputs.\n",
    "\n",
    "## R Code\n",
    "\n",
    "```{r}\n",
    "# Load required package\n",
    "library(tidyverse)\n",
    "\n",
    "# Step 1: Identify SNP columns using prefix pattern\n",
    "snp_cols <- grep(\"^(id|ud|wd|dd|fd)[0-9]+$\", names(gwas_input), value = TRUE)\n",
    "\n",
    "# Step 2: Check number of SNPs selected\n",
    "length(snp_cols)      # Should return 3755\n",
    "head(snp_cols, 5)     # Preview first 5 SNPs\n",
    "\n",
    "# Step 3: Initialize list to collect GWAS results\n",
    "gwas_results <- list()\n",
    "\n",
    "# Step 4: Loop over each SNP and fit linear model\n",
    "for (snp in snp_cols) {\n",
    "  # Construct formula dynamically\n",
    "  formula <- as.formula(paste(\"`Plant height` ~ PC1 + PC2 + PC3 +\", snp))\n",
    "  \n",
    "  # Fit model safely\n",
    "  model <- tryCatch(\n",
    "    lm(formula, data = gwas_input),\n",
    "    error = function(e) NULL\n",
    "  )\n",
    "  \n",
    "  # Step 5: If successful, extract coefficient and p-value\n",
    "  if (!is.null(model)) {\n",
    "    coef_table <- summary(model)$coefficients\n",
    "    snp_row <- tail(rownames(coef_table), 1)\n",
    "    \n",
    "    gwas_results[[snp]] <- tibble(\n",
    "      SNP = snp,\n",
    "      Estimate = coef_table[snp_row, \"Estimate\"],\n",
    "      P_value = coef_table[snp_row, \"Pr(>|t|)\"]\n",
    "    )\n",
    "  }\n",
    "}\n",
    "\n",
    "# Step 6: Combine results and sort by p-value\n",
    "gwas_df <- bind_rows(gwas_results) %>%\n",
    "  arrange(P_value)\n",
    "\n",
    "# Step 7: Save the GWAS results for visualization\n",
    "write_csv(gwas_df, \"data/gwas_results.csv\")\n",
    "\n",
    "# Step 8: Preview top hits\n",
    "head(gwas_df, 10)\n",
    "```\n",
    "\n",
    "> ✅ Takeaway: This loop scans 3,755 SNPs genome-wide and outputs a clean summary table with effect sizes and p-values — ready for visualization using Manhattan and QQ plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b423a214",
   "metadata": {},
   "source": [
    "# How do you create a Manhattan plot from GWAS results using the `ggplot2` package?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "A Manhattan plot visualizes the results of a genome-wide association study (GWAS) by plotting each SNP’s chromosomal position against the –log10(p-value) of its association with a trait. High peaks represent SNPs with strong associations.\n",
    "\n",
    "To create a Manhattan plot using the `ggplot2` package:\n",
    "\n",
    "- You must first merge the GWAS result table with SNP position data (e.g., from a `.map` file).\n",
    "- The –log10(p-value) is computed to scale the plot.\n",
    "- Cumulative genomic positions are calculated to plot SNPs across chromosomes on a continuous axis.\n",
    "- Alternating colors help visually separate chromosomes.\n",
    "\n",
    "## R Code\n",
    "\n",
    "```{r}\n",
    "# Load required libraries\n",
    "library(tidyverse)\n",
    "\n",
    "# Step 1: Load GWAS results and SNP position data\n",
    "gwas_df <- read_csv(\"data/gwas_results.csv\")\n",
    "map_df <- read_tsv(\"data/sativas413.map\", \n",
    "                   col_names = c(\"CHR\", \"SNP\", \"GEN_DIST\", \"BP_POS\"),\n",
    "                   show_col_types = FALSE)\n",
    "\n",
    "# Step 2: Merge GWAS results with chromosome position\n",
    "gwas_annotated <- left_join(gwas_df, map_df, by = \"SNP\") %>%\n",
    "  drop_na()  # Remove SNPs with missing position\n",
    "\n",
    "# Step 3: Compute cumulative position for plotting across chromosomes\n",
    "gwas_annotated <- gwas_annotated %>%\n",
    "  arrange(CHR, BP_POS) %>%\n",
    "  group_by(CHR) %>%\n",
    "  mutate(BP_CUM = BP_POS + ifelse(row_number() == 1, 0, lag(cumsum(BP_POS), default = 0))) %>%\n",
    "  ungroup()\n",
    "\n",
    "# Step 4: Compute –log10(p-value) and color group\n",
    "gwas_annotated <- gwas_annotated %>%\n",
    "  mutate(logP = -log10(P_value),\n",
    "         CHR = as.factor(CHR),\n",
    "         color_group = as.integer(CHR) %% 2)\n",
    "\n",
    "# Step 5: Plot Manhattan plot\n",
    "ggplot(gwas_annotated, aes(x = BP_CUM, y = logP, color = as.factor(color_group))) +\n",
    "  geom_point(alpha = 0.7, size = 1.2) +\n",
    "  scale_color_manual(values = c(\"#003b4a\", \"dodgerblue\")) +\n",
    "  labs(title = \"Manhattan Plot Using ggplot2\",\n",
    "       x = \"Genomic Position\", y = expression(-log[10](p))) +\n",
    "  theme_minimal(base_size = 14) +\n",
    "  theme(legend.position = \"none\",\n",
    "        panel.grid.major.x = element_blank(),\n",
    "        panel.grid.minor.x = element_blank())\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de6c0c1",
   "metadata": {},
   "source": [
    "> ✅ Takeaway: The ggplot2 package allows full control over layout, color, and formatting when visualizing SNP–trait associations across the genome in a Manhattan plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9c4de8",
   "metadata": {},
   "source": [
    "# How do you create a Manhattan plot from GWAS results using the `qqman` package?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "The `qqman` package provides a convenient way to create Manhattan plots directly from GWAS result tables. A Manhattan plot displays each SNP's –log10(p-value) along its genomic position, helping identify regions with strong associations.\n",
    "\n",
    "The function `manhattan()` expects a data frame with these key columns:\n",
    "\n",
    "- `CHR`: Chromosome number  \n",
    "- `BP`: Base-pair position  \n",
    "- `SNP`: SNP identifier  \n",
    "- `P`: P-value from the association test\n",
    "\n",
    "You can prepare this by merging your GWAS result table with a `.map` file containing SNP positions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e051c9",
   "metadata": {},
   "source": [
    "## R Code\n",
    "\n",
    "```{r}\n",
    "# Load required libraries\n",
    "library(tidyverse)\n",
    "library(qqman)\n",
    "\n",
    "# Step 1: Load GWAS results\n",
    "gwas_df <- read_csv(\"data/gwas_results.csv\")\n",
    "\n",
    "# Step 2: Load SNP position data (.map file)\n",
    "map_df <- read_tsv(\"data/sativas413.map\", \n",
    "                   col_names = c(\"CHR\", \"SNP\", \"GEN_DIST\", \"BP\"),\n",
    "                   show_col_types = FALSE)\n",
    "\n",
    "# Step 3: Merge results with map data\n",
    "gwas_annotated <- left_join(gwas_df, map_df, by = \"SNP\") %>%\n",
    "  select(SNP, CHR, BP, P = P_value) %>%\n",
    "  drop_na()\n",
    "\n",
    "# Step 4: Create Manhattan plot using qqman\n",
    "manhattan(gwas_annotated,\n",
    "          main = \"Manhattan Plot of GWAS Results\",\n",
    "          col = c(\"grey30\", \"dodgerblue\"),\n",
    "          cex = 0.6,\n",
    "          cex.axis = 0.9,\n",
    "          las = 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb86fa",
   "metadata": {},
   "source": [
    "> ✅ Takeaway: The qqman package offers a fast and simple way to create publication-ready Manhattan plots by plotting –log10(p-values) across the genome using SNP coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3670557",
   "metadata": {},
   "source": [
    "# How do you create a QQ plot from GWAS results using `qqman` and `ggplot2`?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "A QQ (quantile–quantile) plot compares the distribution of observed p-values from a GWAS with the expected distribution under the null hypothesis. It is a diagnostic tool to detect population structure, inflation, or true associations.\n",
    "\n",
    "You can use:\n",
    "\n",
    "- ✅ `qqman::qq()` for a fast and simple plot  \n",
    "- ✅ `ggplot2` for customization and control over styling and annotations\n",
    "\n",
    "Both approaches produce a similar result but are suited to different use cases.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff65fed",
   "metadata": {},
   "source": [
    "## A. Using the `qqman` package\n",
    "\n",
    "```{r}\n",
    "# Load required libraries\n",
    "library(tidyverse)\n",
    "library(qqman)\n",
    "\n",
    "# Step 1: Load GWAS results\n",
    "gwas_df <- read_csv(\"data/gwas_results.csv\")\n",
    "\n",
    "# Step 2: Create QQ plot using qqman\n",
    "qq(gwas_df$P_value,\n",
    "   main = \"QQ Plot of GWAS Results (qqman)\")\n",
    "```\n",
    "\n",
    "> 🟢 Simple and fast, but limited in customization (no legend or theming)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb41d812",
   "metadata": {},
   "source": [
    "## B. Using `ggplot2` for more control\n",
    "\n",
    "```{r}\n",
    "# Load required library\n",
    "library(tidyverse)\n",
    "\n",
    "# Step 1: Load GWAS results\n",
    "gwas_df <- read_csv(\"data/gwas_results.csv\")\n",
    "\n",
    "# Step 2: Calculate expected vs observed -log10(p)\n",
    "gwas_df <- gwas_df %>%\n",
    "  filter(!is.na(P_value)) %>%\n",
    "  mutate(observed = -log10(sort(P_value)),\n",
    "         expected = -log10(ppoints(n())))\n",
    "\n",
    "# Step 3: Create QQ plot with reference line using ggplot2\n",
    "ggplot(gwas_df, aes(x = expected, y = observed)) +\n",
    "  geom_abline(slope = 1, intercept = 0, color = \"red\", linetype = \"dashed\") +\n",
    "  geom_point(size = 1.2, alpha = 0.6, color = \"steelblue\") +\n",
    "  labs(title = \"QQ Plot of GWAS Results (ggplot2)\",\n",
    "       x = \"Expected -log10(p)\",\n",
    "       y = \"Observed -log10(p)\") +\n",
    "  theme_minimal(base_size = 14)\n",
    "```\n",
    "\n",
    "> ✅ Takeaway: The red dashed line represents the expected distribution of p-values under the null hypothesis. Deviations above the line suggest potential true associations or population structure. Use qqman for simplicity or ggplot2 for full customization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f4760e",
   "metadata": {},
   "source": [
    "# How do you apply multiple testing correction to GWAS results?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "In GWAS, thousands of SNPs are tested for association with a trait. This increases the chance of false positives. To control this, we apply **multiple testing correction** methods such as:\n",
    "\n",
    "- **Bonferroni correction**: Very strict; divides the alpha level (e.g., 0.05) by the number of tests\n",
    "- **False Discovery Rate (FDR)**: A more flexible method that controls the proportion of false positives among significant results (e.g., Benjamini-Hochberg)\n",
    "\n",
    "This helps identify **statistically significant SNPs** while accounting for the large number of tests.\n",
    "\n",
    "## R Code\n",
    "\n",
    "```{r}\n",
    "# Load required packages\n",
    "library(tidyverse)\n",
    "\n",
    "# Step 1: Load GWAS results\n",
    "gwas_df <- read_csv(\"data/gwas_results.csv\")\n",
    "\n",
    "# Step 2: Add Bonferroni-corrected threshold\n",
    "n_tests <- nrow(gwas_df)\n",
    "bonf_threshold <- 0.05 / n_tests\n",
    "\n",
    "# Step 3: Apply FDR correction using p.adjust\n",
    "gwas_df <- gwas_df %>%\n",
    "  mutate(FDR = p.adjust(P_value, method = \"BH\"))\n",
    "\n",
    "# Step 4: Extract significant SNPs\n",
    "significant_bonf <- gwas_df %>%\n",
    "  filter(P_value < bonf_threshold)\n",
    "\n",
    "significant_fdr <- gwas_df %>%\n",
    "  filter(FDR < 0.05)\n",
    "\n",
    "# Step 5: Output summary\n",
    "cat(\"Bonferroni threshold:\", bonf_threshold, \"\\n\")\n",
    "cat(\"Number of SNPs passing Bonferroni:\", nrow(significant_bonf), \"\\n\")\n",
    "cat(\"Number of SNPs passing FDR < 0.05:\", nrow(significant_fdr), \"\\n\")\n",
    "```\n",
    "\n",
    "> ✅ Takeaway: Multiple testing correction is essential in GWAS. Bonferroni is strict but conservative, while FDR balances sensitivity and specificity. Always report how significance was determined.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b487121",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "\n",
    "After applying multiple testing correction to the GWAS results:\n",
    "\n",
    "- **Bonferroni threshold**: `1.331558e-05`  \n",
    "  This is the genome-wide significance level calculated by:\n",
    "\n",
    "*alpha_bonf = 0.05 / 3755 ≈ 1.33 × 10⁻⁵*\n",
    "\n",
    "\n",
    "Any SNP with a raw p-value below this threshold is considered **highly significant**, even under the strictest correction method (controlling the family-wise error rate).\n",
    "\n",
    "- **Number of SNPs passing Bonferroni**: `250`  \n",
    "These are the **strongest associations**, with extremely low p-values. They're unlikely to be false positives and are good candidates for follow-up analysis or functional validation.\n",
    "\n",
    "- **Number of SNPs passing FDR < 0.05**: `1265`  \n",
    "These SNPs are considered statistically significant under a **False Discovery Rate (FDR) of 5%**. This means that, on average, only 5% of these hits are expected to be false positives. It’s a more permissive method that helps capture broader signals.\n",
    "\n",
    "### Summary Table\n",
    "\n",
    "| Correction Method | Threshold           | Significant SNPs | Interpretation                             |\n",
    "|:-------------------|:---------------------|:------------------|:---------------------------------------------|\n",
    "| Bonferroni        | `1.33e-05`          | 250              | Very strict; strong confidence              |\n",
    "| FDR (BH)          | `adjusted < 0.05`   | 1265             | Balanced; allows more discovery, some risk  |\n",
    "\n",
    "> ✅ **Takeaway:** Use Bonferroni to identify high-confidence SNPs and FDR to explore additional signals while controlling the expected proportion of false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2a9553",
   "metadata": {},
   "source": [
    "# How do you create a volcano plot from GWAS results using `ggplot2`?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "A volcano plot is a powerful way to visualize both the **effect size** and **statistical significance** of SNPs in GWAS results. Each point represents a SNP, plotted by:\n",
    "\n",
    "- **X-axis**: Effect size (regression coefficient)\n",
    "- **Y-axis**: –log10(p-value), indicating significance\n",
    "\n",
    "This plot highlights SNPs with:\n",
    "- Large effect sizes\n",
    "- Low p-values (high significance)\n",
    "- Or both\n",
    "\n",
    "You can also add horizontal and vertical reference lines to help interpret thresholds.\n",
    "\n",
    "## R Code\n",
    "\n",
    "```{r}\n",
    "# Load required libraries\n",
    "library(tidyverse)\n",
    "\n",
    "# Step 1: Load GWAS results\n",
    "gwas_df <- read_csv(\"data/gwas_results.csv\")\n",
    "\n",
    "# Step 2: Compute –log10(p-value)\n",
    "gwas_df <- gwas_df %>%\n",
    "  mutate(logP = -log10(P_value))\n",
    "\n",
    "# Step 3: Create volcano plot\n",
    "ggplot(gwas_df, aes(x = Estimate, y = logP)) +\n",
    "  geom_point(alpha = 0.6, color = \"grey40\") +\n",
    "  geom_hline(yintercept = -log10(0.05 / nrow(gwas_df)), linetype = \"dashed\", color = \"red\") +  # Bonferroni line\n",
    "  geom_vline(xintercept = 0, linetype = \"dotted\", color = \"black\") +  # Null effect line\n",
    "  labs(title = \"Volcano Plot of GWAS Results\",\n",
    "       x = \"Effect Size (Estimate)\",\n",
    "       y = expression(-log[10](p))) +\n",
    "  theme_minimal(base_size = 14)\n",
    "\n",
    "\n",
    "# Add significance status\n",
    "gwas_df <- gwas_df %>%\n",
    "  mutate(significant = P_value < 0.05 / nrow(gwas_df))\n",
    "\n",
    "# Re-plot with color by significance\n",
    "ggplot(gwas_df, aes(x = Estimate, y = logP, color = significant)) +\n",
    "  geom_point(alpha = 0.7) +\n",
    "  scale_color_manual(values = c(\"grey70\", \"red\")) +\n",
    "  geom_hline(yintercept = -log10(0.05 / nrow(gwas_df)), linetype = \"dashed\", color = \"red\") +\n",
    "  geom_vline(xintercept = 0, linetype = \"dotted\", color = \"black\") +\n",
    "  labs(title = \"Volcano Plot with Bonferroni Threshold\",\n",
    "       x = \"Effect Size (Estimate)\",\n",
    "       y = expression(-log[10](p))) +\n",
    "  theme_minimal(base_size = 14) +\n",
    "  theme(legend.title = element_blank())\n",
    "```\n",
    "\n",
    "> ✅ Takeaway: A volcano plot shows the balance between effect size and significance. SNPs with both large effects and low p-values appear as extreme points in the top left or right quadrants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1530b1d7",
   "metadata": {},
   "source": [
    "# How do you identify genome-wide significant SNP hits and save them for downstream analysis?\n",
    "\n",
    "## Explanation\n",
    "\n",
    "Once GWAS results are generated and corrected for multiple testing, the next step is to identify statistically significant SNPs. A common threshold is the **Bonferroni-adjusted p-value**, which accounts for the number of tests.\n",
    "\n",
    "You can:\n",
    "\n",
    "- Filter SNPs below the Bonferroni threshold\n",
    "- Annotate them with chromosome and base-pair position using the `.map` file\n",
    "- Save the output for use in downstream steps like gene annotation or reporting\n",
    "\n",
    "## R Code\n",
    "\n",
    "```{r}\n",
    "# Load required libraries\n",
    "library(tidyverse)\n",
    "\n",
    "# Step 1: Load GWAS results\n",
    "gwas_df <- read_csv(\"data/gwas_results.csv\")\n",
    "\n",
    "# Step 2: Calculate Bonferroni threshold\n",
    "n_tests <- nrow(gwas_df)\n",
    "bonf_threshold <- 0.05 / n_tests  # ≈ 1.33e-05 for 3755 SNPs\n",
    "\n",
    "# Step 3: Filter significant hits\n",
    "significant_hits <- gwas_df %>%\n",
    "  filter(P_value < bonf_threshold) %>%\n",
    "  arrange(P_value)\n",
    "\n",
    "# Step 4: Load SNP position data\n",
    "map_df <- read_tsv(\"data/sativas413.map\",\n",
    "                   col_names = c(\"CHR\", \"SNP\", \"GEN_DIST\", \"BP\"),\n",
    "                   show_col_types = FALSE)\n",
    "\n",
    "# Step 5: Annotate significant SNPs with position\n",
    "annotated_hits <- left_join(significant_hits, map_df, by = \"SNP\") %>%\n",
    "  select(SNP, CHR, BP, Estimate, P_value)\n",
    "\n",
    "# Step 6: Save for downstream analysis\n",
    "write_csv(annotated_hits, \"data/significant_snps_bonferroni.csv\")\n",
    "\n",
    "# Step 7: Preview top hits\n",
    "head(annotated_hits, 10)\n",
    "```\n",
    "\n",
    "> ✅ Takeaway: Identifying and saving genome-wide significant SNPs ensures a clean input for downstream analysis such as gene annotation, pathway mapping, or publication reporting.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
